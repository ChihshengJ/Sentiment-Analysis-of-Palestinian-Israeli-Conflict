# Code Directory Explanation

Within the `Code` folder, you will find several Jupyter notebooks, each with a specific purpose for the overall project:

- `Crawler.ipynb`: This notebook contains the code for a web crawler that utilizes the Python Reddit API Wrapper (PRAW) to access and scrape text data from Reddit. It is designed to interact with Reddit's API efficiently and fetch data as per the project's requirements.

- `Dataset_Combination.ipynb`: This notebook is tasked with the job of deduplicating and merging multiple blocks of crawled data into a single, coherent dataset. It ensures that the final dataset is clean and consolidated for subsequent analysis.

- `Statistics.ipynb`: This notebook is dedicated to statistical analysis and the exploration of data insights. It employs a variety of data science methodologies to understand the data deeply and to extract meaningful information from it.

- `XLNet.ipynb`: Here lies the code for the XLNet model that has been trained as part of this project. This notebook will detail the training process, including model configuration, training procedures, and performance evaluation.

- `Combined_Code.ipynb`: This notebook serves as the integration point for all the separate code scripts. It is where all the individual components come together, allowing for a holistic view and execution of the project's codebase.

Each notebook is well-documented to facilitate understanding of the code and its function within the larger project context.

